devtools::install_github("ropenscilabs/ponyexpress")
--version
r --version
R --version
version
version
1:50
names <- ("Lilia", "Parker", "Matt", "Jeffrey")
names <- ("Lilia", "Parker", "Matt", "Jeffrey")
names <- ('Lilia', 'Parker', 'Matt', 'Jeffrey')
x <- ('Lilia', 'Parker', 'Matt', 'Jeffrey')
x <- c('Lilia', 'Parker', 'Matt', 'Jeffrey')
xx <- combinations<-(4,3,x)
xx <- combinations(4,3,x)
library(gtools)
xx <- combinations(4,3,x)
View(xx)
View(xx)
xx <- combinations(4,3,x)
xx <- combinations(4,2,x)
x = 20
# Twice as many filler sentences as test sentences
test_items = x
filler_items = 3*test_items
total_items = test_items + filler_items
print(total_items)
x = 30
source('~/gtd/courses/Honors-Thesis/code/stimuli.R', echo=TRUE)
# Assuming 30s per judgment
run_time = total_items*0.5
print(run_time)
test_items
help("combn")
combn(30,30)
combn([1:30], 30)
combn(1:30, 30)
# Twice as many filler sentences as test sentences (Probably half grammatical, half ungrammatical)
test_items = x
filler_items = 2*test_items
total_items = test_items + filler_items
print(total_items)
# Assuming 30s per judgment
run_time = total_items*0.5
print(run_time)
# Twice as many filler sentences as test sentences (Probably half grammatical, half ungrammatical)
test_items = x
# Twice as many filler sentences as test sentences (Probably half grammatical, half ungrammatical)
x = 30
test_items = x
filler_items = 2*test_items
total_items = test_items + filler_items
print(total_items)
# Assuming 30s per judgment
run_time = total_items*0.5
print(run_time)
# Counterbalancing: creating many tokens for each condition and presenting them across conditions?
# Heather, p. 23: weak prepositions cannnot participate in stranding; p. 41 -Functional particles and adverbs
# Heather, p. 23: weak prepositions cannnot participate in stranding; p. 41 -Functional particles and adverbs
# p. Stranding works with +Functional semi-lexical and functional prepositions
# Sentence types: Declarative, Interrogative, Embedded Interrogative, Imperative
# Sentence types: Declarative, Interrogative, Embedded Interrogative, Imperative
# Sentence components: verbs, variety of prepositions of different types (See Heather's thing)
# Make sure all nouns are frequent
# Twice as many filler sentences as test sentences (Probably half grammatical, half ungrammatical)
x = 30
test_items = x
filler_items = 2*test_items
total_items = test_items + filler_items
print(total_items)
# Assuming 30s per judgment
run_time = total_items*0.5
# Twice as many filler sentences as test sentences (Probably half grammatical, half ungrammatical)
x = 30
test_items = x
filler_items = 2*test_items
total_items = test_items + filler_items
print(total_items)
# Assuming 30s per judgment
run_time = total_items*0.5
print(run_time)
source('~/gtd/courses/Honors-Thesis/code/stimuli.R', echo=TRUE)
# Twice as many filler sentences as test sentences (Probably half grammatical, half ungrammatical)
x = 40
test_items = x
filler_items = 2*test_items
total_items = test_items + filler_items
print(total_items)
# Assuming 30s per judgment
run_time = total_items*0.5
print(run_time)
# Twice as many filler sentences as test sentences (Probably half grammatical, half ungrammatical)
x = 25
source('~/gtd/courses/Honors-Thesis/code/stimuli.R', echo=TRUE)
25/4
# Twice as many filler sentences as test sentences (Probably half grammatical, half ungrammatical)
x = 28
test_items = x
filler_items = 2*test_items
total_items = test_items + filler_items
print(total_items)
# Assuming 30s per judgment
run_time = total_items*0.5
print(run_time)
source('~/gtd/courses/Honors-Thesis/code/stimuli.R', echo=TRUE)
15*0.75
total_items
96 * 4
96 / 4
# Twice as many filler sentences as test sentences (Probably half grammatical, half ungrammatical)
x = 32  # 8 token in each trial
test_items = x
filler_items = 2*test_items  # For forced choice, this would actually be total judgments
total_items = test_items + filler_items # 96 total, 4 blocks = 24 in each block, out of which 8 are tokens
# Numbers of participants
num_conditions = 4
# Numbers of participants
num_conditions = 4
num_participants_per_condition = 50
pay_per_participant = length_of_task * mturk_hourly
length_of_task = 1/3 #hr
pay_per_participant = length_of_task * mturk_hourly
# Numbers of participants
num_conditions = 4
num_participants_per_condition = 50
mturk_hourly = 6
length_of_task = 1/3 #hr
pay_per_participant = length_of_task * mturk_hourly
# Numbers of participants
num_conditions = 4
num_participants_per_condition = 50
mturk_hourly = 8
length_of_task = 1/3 #hr
pay_per_participant = length_of_task * mturk_hourly
# Numbers of participants
num_conditions = 4
num_participants_per_condition = 50
mturk_hourly = 9
length_of_task = 1/3 #hr
pay_per_participant = length_of_task * mturk_hourly
# Numbers of participants
num_conditions = 4
num_participants_per_condition = 50
mturk_hourly = 12
length_of_task = 1/3 #hr
pay_per_participant = length_of_task * mturk_hourly
num_conditions * num_participants_per_condition = study_1_n
pay_per_participant = length_of_task * mturk_hourly
num_conditions * num_participants_per_condition -> study_1_n
study_1_payment = study_1_n * pay_per_participant
# assuming the same cost for second study
study_1_payment*2 -> payment_total
# Twice as many filler sentences as test sentences (Probably half grammatical, half ungrammatical)
x = 32  # 8 token in each block
test_items = x
# Twice as many filler sentences as test sentences (Probably half grammatical, half ungrammatical)
x = 32  # 8 token in each block
test_items = x
filler_items = 2*test_items  # For forced choice, this would actually be total judgments
total_items = test_items + filler_items # 96 total, 4 blocks = 24 in each block, out of which 8 are tokens
source('~/clean_load3.R', echo=TRUE)
View(current_counts)
